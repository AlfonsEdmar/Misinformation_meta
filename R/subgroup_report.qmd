---
title: "Subgroup analyses"
format: pdf
editor: visual
---

```{r include=FALSE}
knitr::opts_chunk$set(echo=FALSE)
```

## Age-subgroup analysis.

### Full moderation model

This is the subgroup analysis on the mean age on our full moderator model

```{r, echo=FALSE, include=FALSE}
library(metafor)
library(here)
library(tidyverse)
```


```{r, echo=FALSE}
meta_age <- read_rds(here('output/misinformation_meta_age.rds'))
summary(meta_age)
```

The average adjusted true effect is .7 with a standard error of .19. Post exposure retention intervals has a small but negative effect with the ME decreasing by .0002 for each hour after exposure(poor scaling maybe). Post-event warnings reduce the effect by .3 for each warning made. Control accuracy increases the effect by 2 for each deviation from the average control accuracy. Age does not have an impact on the effect.

Next we can look at the random effects. For the control type, consistent information produces the largest effects, even when adjusting for the control accuracy which is interesting. Providing no information in the control seems to provide the most clinical non-nuisance inducing misinformation effect.

```{r echo=FALSE}
ranef.rma.mv(meta_age)$control_type
```

For the modal modality, field experiments produces the largest effects, but this effect is small and given the low sample size of field studies might not be an entirely reliable effect.

```{r echo=FALSE}
ranef.rma.mv(meta_age)$modality
```

The test type does not seem to have an overly large impact on the effect, but it is clear that using the modified test heavily reduces the misinformation effect.

```{r echo=FALSE}
ranef.rma.mv(meta_age)$test_type
```

The test medium also don't seem to have much of an impact on the effect size, which is good and quite reasonable to me.

```{r echo=F}
ranef.rma.mv(meta_age)$test_medium
```

The exposure medium does not carry any meaningful impact.

```{r echo=FALSE}
round(ranef.rma.mv(meta_age)$exposure_medium, 8)
```

The population category also do not indicate any meaningful differences across groups.

```{r echo=FALSE}
round(ranef.rma.mv(meta_age)$population, 8)
```

### Removing the control accuracy from the model

This is the results without the control accuracy.

```{r echo=FALSE}
meta_age_no_acc <- read_rds(here('output/misinformation_meta_age_no_accuracy.rds'))
summary(meta_age_no_acc)
```

There are no large differences across the models, but the variance in true effects from the test medium disappears when we remove control accuracy from the model. This could be due to test medium having a large impact on the control accuracy. Notably, the event materials also do introduce variation in effects beyond what would be expected from random sampling.

### Quadratic transformation on age

This is the quadratic transformed age variable model. It does not make an impact on how we view the model results.

```{r echo=FALSE}
meta_age_quad <- read_rds(here('output/misinformation_meta_quad_age.rds'))
summary(meta_age_quad)
```

### Age as a category variable

Lastly, we have a a model where we treat age as a category variable on 4 levels with 1 being children ages 0-5, 2 being ages 5-17, 3 being 18-40, and 4 being 40+. The reference category were the youngest children ages 0-5.

```{r echo=F}
meta_age_cat <- read_rds(here('output/misinformation_meta_age_cat.rds'))
summary(meta_age_cat)
```

By treating the ages as categories we find no differences in ages compared to the children(who would presumably perform the worst) except for children between 6 and 17 who had a slightly larger misinformation effects at .21.

## Subgroup analysis across incentives

Here we examine whether the incentive structure makes differences in the misinformation effect. The incentive variable is a factor with the reference group being given no incentive. It does not seem like incentive carries any strong implications for the ME. However, it could be the case that course credit as compared to no incentives increases the effect by .21, indicating that motivation to participate *might* increase the effect. It should be noted that course_credit was by far the most common incentive.

```{r echo=FALSE}
meta_incent <- read_rds(here('output/misinformation_meta_incent.rds'))
summary(meta_incent)
```

## Subgroup analysis of item-centrality

Here we look at the 17 studies that manipulated the centrality of the items. It does not seem like any variables in this model significantly impact the misinformation effect outside of the post exposure retention interval with a small negative effect.

```{r echo=FALSE}
meta_centrality <- read_rds(here('output/misinformation_meta_centrality.rds'))
summary(meta_centrality)
```

If we remove the control accuracy variable, the results does not change in any meaningful way.

```{r echo=FALSE}
meta_centrality_no_acc <- read_rds(here('output/misinformation_meta_centrality_no_acc.rds'))
summary(meta_centrality_no_acc)
```
